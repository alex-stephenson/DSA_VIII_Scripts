<<<<<<< Updated upstream
library(cleaninginspectoR, quietly = T)
library(koboAPI, quietly = T)
library(openxlsx, quietly = T)
library(readxl, quietly = T)
library(kableExtra, quietly = T)
library(cleaningtools, quietly = T)
library(robotoolbox, quietly = T)
library(ImpactFunctions)
## Hard code values
consent <- "consent"
mindur <- 30
maxdur <- 90
## Set this to TRUE if you want to select the date through the bat file. If FALSE you need to set the date in the script.
dynamic_date <- FALSE ## if false the date must be set in line 184
## set this if you want to access the data from the server. If you are going to choose the file choose TRUE
access_from_server <- TRUE ## if false the file will be manually selected
=======
} else {
# If the file doesn't exist, create a new Excel file
wb <- createWorkbook()
addWorksheet(wb, "Sheet1")
writeData(wb, sheet = "Sheet1", data)
# Save the workbook
saveWorkbook(wb, file_path)
}
}
# Iterate over the list of data frames and save them
purrr::walk(contact_data_by_fo, ~ {
fo_name <- unique(.$Responsible_FO)  # Extract the Responsible_FO name
write_or_append_excel(., fo_name, output_dir = getwd())  # Call the function to write or append to Excel
})
contact_data_by_fo
group_by_fo <- df %>%
dplyr::group_by(Responsible_FO)
group_by_fo
group_by_fo %>% filter(Responsible_FO == "No_FO")
df <- df %>%
left_join(field_officer_location, by = join_by(idp_code == `CCCM IDP Site Code`))
df %>% filter(Responsible_FO == "No_FO")
df <- df %>%
left_join(field_officer_location, by = join_by(idp_code == `CCCM IDP Site Code`))
df$Responsible_FO
user_login <- Sys.info()[["user"]]
wd_path <- sprintf(r"(C:/Users/%s/ACTED/IMPACT SOM - 02_Research/01_REACH/Team - Displacement to Durable Solutions (DDS)/03_DDSU/SOMXX_DSA/03_Data_Analysis/DSA_VIII_Scripts)", user_login)
setwd(wd_path)
if (access_from_server == TRUE) {
source(sprintf(r"(C:\Users\%s\ACTED\IMPACT SOM - 02_Research\01_REACH\Data Team\02_Functions\access_kobo_api.r)", user_login))
df <- get_kobo_data(asset_id = "a38DR4AhAH2rDqP6e5YHLm")
print("Kobo data successfully accessed from server")
} else {
df <- readxl::read_excel(r"(input/SOM2204_CCCM_DSA_July.xlsx)") ###### remove this once no longer required ###############
district_file <- read.csv("input/idp_list.csv")
koboToolPath = "input/tool/REACH_2023_SOM_DSA_Survey_Tool.xlsx"
questions = import(koboToolPath,sheet="survey") %>%
filter(!is.na(name))
choices = import(koboToolPath,sheet="choices")
}
site_path <- sprintf(r"(C:\Users\%s\ACTED\IMPACT SOM - 02_Research\01_REACH\Team - Displacement to Durable Solutions (DDS)\03_DDSU\SOMXX_DSA\01_Research_Design\Reference_Data\idp-site-master-list-sep-2024.xlsx)", user_login)
site_data <- read_excel(site_path, sheet = "Sites for Field") %>%
mutate(District = str_to_title(District))
## read in FO site and locations
fo_base_assingment_str <- sprintf(r"(C:\Users\%s\ACTED\IMPACT SOM - 02_Research\01_REACH\Team - Displacement to Durable Solutions (DDS)\03_DDSU\SOMXX_DSA\03_Data_Analysis\DSA_VIII_Scripts\input/Field team work distribution.xlsx)", user_login)
fo_district_mapping <- read_excel(fo_base_assingment_str) %>%
mutate(Locations = str_to_title(Locations))
field_officer_location <- site_data %>%
left_join(fo_district_mapping, by = join_by("District" == "Locations")) %>%
distinct(`CCCM IDP Site Code`, District, Responsible_FO) %>%
mutate(Responsible_FO = str_replace_all(Responsible_FO, "/", "_"),
Responsible_FO = ifelse(Responsible_FO == "" | is.na(Responsible_FO), "No_FO", Responsible_FO)) %>%
filter(!is.na(`CCCM IDP Site Code`))
field_officer_location$Responsible_FO <- ifelse(field_officer_location$Responsible_FO == "" | is.na(field_officer_location$Responsible_FO), "No_FO", field_officer_location$Responsible_FO)
dynamic_date <- FALSE
args <- commandArgs(trailingOnly = T)
print(args)
date_selection <- args[1]
if (length(args) == 2) {
custom_date_option <- args[2]
}
#if (dynamic_date) {
#  date_selection <- menu(c("Yesterday's date", "Today's date", "Specific date"),
#                         title = "Choose the date for which you want to clean data", graphics = TRUE)
if (dynamic_date) {
if (date_selection == "1" || date_selection == "yesterday") {
date_to_filter <- Sys.Date() - 1
message("You selected yesterday's date.")
} else if (date_selection == "today") {
date_to_filter <- Sys.Date()
message("You selected today's date.")
} else if (custom_date_option == 3) {
specific_date <- args[1]
date_to_filter <- as.Date(specific_date)
print("Date successfully filtered!")
} else {
stop("Invalid selection or exit chosen.")
}
print(date_to_filter)
df <- df %>%
left_join(district_file, by = c("idp_code")) %>%
mutate(submission_date = format(ymd_hms(`_submission_time`), "%Y-%m-%d")) %>%
filter(submission_date == date_to_filter)
} else {
df <- df %>%
left_join(district_file, by = c("idp_code")) %>%
mutate(submission_date = format(ymd_hms(`_submission_time`), "%Y-%m-%d")) %>%
filter(submission_date == "2023-10-08")
}
if (nrow(df) == 0) {
stop("Data ingested is empty")
}
## add a flag for whether there is a referral included for later
df <- df %>%
mutate(referral_yn = case_when(
str_starts(referral_person, "Yes") ~ "Yes",
str_starts(referral_person, "No") ~ "No",
TRUE ~ NA_character_
))
tool.survey<- questions%>%
filter(name%in%colnames(df))
cols.integer <- tool.survey %>%
filter(type == "integer") %>%
pull(name)
cols.gps <- tool.survey %>%
filter(type == "gps") %>%
pull(name)
cols.characters_one <- tool.survey %>%
filter(str_detect(type, "select_one")) %>%
pull(name)
cols.characters_multiple <- tool.survey %>%
filter(str_detect(type, "select_multiple")) %>%
pull(name)
df <- mutate_at(df, cols.gps, as.integer)
df <- mutate_at(df, cols.integer, as.integer)
df <- mutate_at(df, cols.characters_one, as.character)
df <- mutate_at(df, cols.characters_multiple, as.character)
time_check <- function(df, time_min, time_max){
df <- df %>% mutate(interview_duration = difftime(as.POSIXct(ymd_hms(end)), as.POSIXct(ymd_hms(start)), units = "mins"),
CHECK_interview_duration = case_when(
interview_duration < time_min ~ "Too short",
interview_duration > time_max ~ "Too long",
TRUE ~ "Okay"
)
)
return(df)
}
"%!in%" <- Negate("%in%")
df <- time_check(df, time_min = mindur, time_max = maxdur)
gis_data <- df %>%
filter(interview_duration>=30 & consent=="yes") %>%
select(uuid,start,end,audit,today,enum_name,localisation_region_label,
ki_contact,district_name,idp_code,IDP_Site,contains("gps"),more_info)
gis_master <- readxl::read_excel("gis/gis_master_DSA_VII.xlsx") ## NEEDS UPDATING
gis_data  <- filter(gis_data, uuid %!in% gis_master$uuid)
gis_master <- rbind(gis_data,gis_master)
gis_master <- gis_master [!duplicated(gis_master$uuid),]
#write.xlsx(gis_master,paste("C:\\Users\\aaron.langat\\Documents\\R\\01_DSA\\03_Cleaning\\gis/gis_master.xlsx"))
gis_data <- gis_data [!duplicated(gis_data$uuid),]
n_occur_idp_code <- df %>%
dplyr::count(idp_code) %>%
filter(n > 4)
count_ki_roles_site <- df %>%
group_by(idp_code,ki_role) %>%
dplyr::summarise(n=n()) %>%
filter(n > 1)
check_list <- data.frame(
name = c(
"KI_Consent",
"KI_too_old",
"KI_age_and_role",
"IDP_arrival_time",
"ki_role_camp_structure",
"ki_role_resident",
"small_camp",
"small_families",
"low_number_of_individuals",
"idp_code_count",
"ki_role_per_site"),
check = c(
r"(consent == "no")",
"ki_age == \"90_above\"",
r"((ki_age=="30_49" | ki_age=="18_29") & ki_role=="elder")",
r"((duration_site_established_in_months < 4 & cccm_idps_arrival=="morethansixmonths" | cccm_idps_arrival=="fourtosixmonths")|
(duration_site_established_in_months < 2 & cccm_idps_arrival=="morethansixmonths" | cccm_idps_arrival=="fourtosixmonths"|cccm_idps_arrival=="onetothreemonths")|
(duration_site_established_in_months < 6 & cccm_idps_arrival=="morethansixmonths"))",
r"(ki_role %in% c("gatekeeper", "camp_leader", "site_manager") & camp_structure == "no")",
r"(ki_role == "site_resident" & ki_resident == "no")",
r"(cccm_populationestimates_shelters < 50)",
r"(cccm_populationestimates_families < 100)",
r"(cccm_populationestimates_individuals < 150)",
r"(idp_code %in% n_occur_idp_code$idp_code)",
r"(idp_code %in% count_ki_roles_site$idp_code)"
),
description = c(
"KI has not given consent. Please review why.",
"KI respondent has said they are older than 90. Please check",
"KI age is is less than 50 and his role is an elder",
"IDPs claim they have arrived before the site was set up",
"KI has already identifed him/here self as site manager or gatekeeper, but is reporting that no camp structure exists, please confirm",
"KI has reported their role is site resident but separately said they are not a site resident. Please review with the enumerator.",
"The number shelters in the camp are less then 50, please confirm with enumerator",
"The number of families in the camp are less than 100, please confirm with enumeator",
"The number of individuals in the camp is less than 150. Please confirm with the enumerator",
"The IDP Site has been interviewed more than four times. Please verify.",
"The same role has been interviewed in an IDP site more than once. Please verify"
),
columns_to_clean = c(
"consent",
"ki_age",
"ki_age, ki_role",
"duration_site_established_in_months, cccm_idps_arrival",
"ki_role, camp_structure",
"ki_role, ki_resident",
"cccm_populationestimates_shelters",
"cccm_populationestimates_families",
"cccm_populationestimates_individuals",
"idp_code",
"idp_code"
)
)
outlier_excluded_questions <- questions %>%
filter(type != 'integer') %>%
pull(name) %>%
unique()
# intersect between the dataset and the kobo tool questions to make sure we get a clean list
excluded_questions_in_data <- intersect(colnames(df), outlier_excluded_questions)
df %>%
left_join(field_officer_location, by = join_by(idp_code == `CCCM IDP Site Code`)) %>% filter(is.na(Responsible_FO ))
df %>% filter(idp_code %!in% field_officer_location$`CCCM IDP Site Code`)
df %>% filter(idp_code %!in% field_officer_location$`CCCM IDP Site Code`) %>% write_csv('sites_not_in_list.csv')
df %>% filter(idp_code %!in% field_officer_location$`CCCM IDP Site Code`)
df %>% filter(idp_code %!in% field_officer_location$`CCCM IDP Site Code`) %>% select(idp_site)
df %>% filter(idp_code %!in% field_officer_location$`CCCM IDP Site Code`) %>% select(IDP_Site)
field_officer_location$District
df$district_name
df <- df %>%
left_join(field_officer_location, by = join_by(district_name == district))
access_from_server <- FALSE
>>>>>>> Stashed changes
###################################################
###### STEP 2 - IMPORT DATA AND FUNCTIONS #########
###################################################
#to make the scripts reusable relative file paths should be used
user_login <- Sys.info()[["user"]]
wd_path <- sprintf(r"(C:/Users/%s/ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025/03_Data_Analysis/DSA_VIII_Scripts)", user_login)
setwd(wd_path)
## get data input from the .BAT file we are using to run the script.
args <- commandArgs(trailingOnly = TRUE)
# Parse args into a named list
arg_list <- list()
for (arg in args) {
key_value <- strsplit(arg, "=")[[1]]
if (length(key_value) == 2) {
arg_list[[key_value[1]]] <- key_value[2]
}
}
# Assign default values if certain arguments are missing
username <- arg_list[["username"]] %||% "alex_stephenson"
asset_id <- arg_list[["asset_id"]] %||% "asSj6Aq8kDg5FULShCKbjN"
date_selection <- arg_list[["date_selection"]] %||% NA  # Optional, can be NA
# Use these variables in your code
print(paste("Username:", username))
print(paste("Asset ID:", asset_id))
print(paste("Date Selection:", date_selection))
if (access_from_server == TRUE) {
print("Accessing from server...")
}
df_raw <- get_kobo_data(un = username, asset_id = asset_id)
kobo_asset_list()
audit_files <- robotoolbox::kobo_audit("asSj6Aq8kDg5FULShCKbjN", progress = T)
glimpse(audit_files)
summary(audit_files)
View(audit_files)
audit_files_length <- audit_files %>%
filter(event != "group_questions") %>%
mutate(duration = (start_int - end_int) / 60000)
View(audit_files_length)
audit_files_length <- audit_files %>%
filter(event != "group_questions") %>%
mutate(duration = (end_int - start_int ) / 60000)
View(audit_files_length)
audit_files_length %>% filter(node == "/asSj6Aq8kDg5FULShCKbjN/enum_name")
audit_files_length %>% group_by(`_id`) %>% summarise(iv_len = sum(duration))
audit_files_length %>% group_by(`_id`) %>% summarise(iv_len = sum(duration, na.rm = T))
iv_lengths <- audit_files_length %>% group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T))
df <- df_raw %>%
dplyr::rename(
"survey_uuid" = "uuid",
"uuid" = "_uuid",
"idp_site" = "localisation_site",
`_observation_gps_latitude` = "geopoint_latitude",
`_observation_gps_longitude` = "geopoint_longitude",
`_observation_gps_altitude` = "geopoint_altitude",
`_observation_gps_precision` = "geopoint_precision"
)
df <- df %>%
mutate(
idp_code = case_when(
# Apply the first condition to add "2023-" prefix when date is 12/11/2024 and region is "Banadir"
today == as.Date("2024-11-12") & localisation_region == "SO22" ~ str_replace(idp_code, "^CCCM-", "CCCM-2023-"),
# Apply the second condition to replace "2023" with "2023(U)" for specified site codes
idp_code %in% c("CCCM-2023-SO220117-0353", "CCCM-2023-SO220117-0404",
"CCCM-2023-SO220117-0382", "CCCM-2023-SO220117-0383",
"CCCM-2023-SO220117-0394", "CCCM-2023-SO220117-0414") ~ str_replace(idp_code, "2023", "2023(U)"),
# Otherwise, retain original values
TRUE ~ idp_code
),
nfi_access_dist_min_int_male = case_when(
nfi_access_distance_min_male == 'less_15' ~ 0,
nfi_access_distance_min_male == '15_30' ~ 15,
nfi_access_distance_min_male == '31_60' ~ 31,
nfi_access_distance_min_male == 'more_60' ~ 60,
TRUE ~ 999
),
nfi_access_dist_min_int_female = case_when(
nfi_access_distance_min_fem == 'less_15' ~ 0,
nfi_access_distance_min_fem == '15_30' ~ 15,
nfi_access_distance_min_fem == '31_60' ~ 31,
nfi_access_distance_min_fem == 'more_60' ~ 60,
TRUE ~ 999
)
)
## read in survey data
#district_file <- read.csv("input/idp_list_OLD_INCORRECT.csv")
koboToolPath = sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\02_Data_Collection\01_Tool\REACH_2024_SOM_DSA_Survey_Tool_VIII.xlsx)", user_login)
questions = import(koboToolPath,sheet="survey") %>%
filter(!is.na(name))
choices = import(koboToolPath,sheet="choices")
## read in site level data
site_path <- sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\01_Research_Design\Reference_Data\idp-site-master-list-sep-2024.xlsx)", user_login)
site_data <- read_excel(site_path, sheet = "Sites for Field") %>%
mutate(District = str_to_title(District))
## read in FO site and locations - this data is used to map the respective field officers to each district.
fo_base_assingment_str <- sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\03_Data_Analysis\DSA_VIII_Scripts\input/Field team work distribution.xlsx)", user_login)
fo_district_mapping <- read_excel(fo_base_assingment_str) %>%
mutate(Locations = str_to_title(Locations))
## read in survey data
#district_file <- read.csv("input/idp_list_OLD_INCORRECT.csv")
koboToolPath = sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\02_Data_Collection\01_Tool\REACH_2024_SOM_DSA_Survey_Tool_VIII.xlsx)", user_login)
questions = import(koboToolPath,sheet="survey") %>%
filter(!is.na(name))
choices = import(koboToolPath,sheet="choices")
## read in site level data
site_path <- sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\01_Research_Design\Reference_Data\idp-site-master-list-sep-2024.xlsx)", user_login)
site_data <- read_excel(site_path, sheet = "Sites for Field") %>%
mutate(District = str_to_title(District))
## read in FO site and locations - this data is used to map the respective field officers to each district.
fo_base_assingment_str <- sprintf(r"(C:\Users\%s\ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025\03_Data_Analysis\DSA_VIII_Scripts\input/Field team work distribution.xlsx)", user_login)
fo_district_mapping <- read_excel(fo_base_assingment_str) %>%
mutate(Locations = str_to_title(Locations))
## join site data to field data
field_officer_location <- site_data %>%
left_join(fo_district_mapping, by = join_by("District" == "Locations")) %>%
distinct(`CCCM IDP Site Code`, District, Responsible_FO) %>%
mutate(Responsible_FO = str_replace_all(Responsible_FO, "/", "_"),
Responsible_FO = ifelse(Responsible_FO == "" | is.na(Responsible_FO), "No_FO", Responsible_FO)) %>%
filter(!is.na(`CCCM IDP Site Code`))
##rename any blank values
field_officer_location$Responsible_FO <- ifelse(field_officer_location$Responsible_FO == "" | is.na(field_officer_location$Responsible_FO), "No_FO", field_officer_location$Responsible_FO)
## join the district name to the site df (in the responses it just has the district p code)
df <- df %>%
left_join(choices %>%
filter(!is.na(region))  %>%
select(name, `label::English (en)`) %>%
dplyr::rename(localisation_region_label = `label::English (en)`),
by = join_by("localisation_region" == "name")) %>%
relocate(localisation_region_label, .after = "localisation_region")
df <- df %>%
mutate(referral_yn = case_when(
str_starts(referral_person, "y") ~ "Yes",
str_starts(referral_person, "n") ~ "No",
TRUE ~ NA_character_
))
time_check <- function(df, time_min, time_max){
df <- df %>% mutate(interview_duration = difftime(as.POSIXct(ymd_hms(end)), as.POSIXct(ymd_hms(start)), units = "mins"),
CHECK_interview_duration = case_when(
interview_duration < time_min ~ "Too short",
interview_duration > time_max ~ "Too long",
TRUE ~ "Okay"
)
)
return(df)
}
df <- time_check(df, time_min = mindur, time_max = maxdur)
df$id
View(df)
get_kobo_data
?kobo_data
iv_lengths
df$`_id`
df %>% select(`_id`, interview_duration) %>%
left_join(iv_lengths)
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths)
View(audit_files)
audit_files_length <- audit_files %>%
#  filter(event != "group_questions") %>%
mutate(duration = (end_int - start_int ) / 60000)
iv_lengths <- audit_files_length %>% group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T))
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths)
iv_lengths
iv_lengths %>%
ggplot(aes(iv_len)) +
geom_histogram()
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram()
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram() +
geom_vline(x = 30)
?geom_vline
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram() +
geom_vline(xintercept = 30)
?geom_histogram
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 5) +
geom_vline(xintercept = 30)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 1) +
geom_vline(xintercept = 30)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30) +
scale_x_binned(n.breaks = 10)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
#  geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30) +
scale_x_binned(n.breaks = 10)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram() +
geom_vline(xintercept = 30) +
scale_x_binned(n.breaks = 10)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30) +
scale_x_continuous(breaks = 10)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30) +
scale_x_continuous(breaks = seq(0, 120, 5))
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 30) +
scale_x_continuous(breaks = seq(0, 120, 10))
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths)
View(iv_lengths)
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths)
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duratio - iv_len)
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
options(scipen = 999)
df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
time_delta <- df %>% select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
View(time_delta)
time_issues <- time_delta %>%
filter(iv_len < 30)
View(time_issues)
time_issues <- time_delta %>%
filter(iv_len < 30,
interview_duration > 30)
time_issues <- time_delta %>%
filter(iv_len < 30,
interview_duration > 30,
time_delta > 10)
View(time_issues)
View(audit_files)
audit_files %>% filter(`_id` == "2407107")
audit_files %>% filter(`_id` == "2407107") %>% View()
df %>% filter(`_id` == "2407107") %>% View()
audit_files %>% filter(`_id` == "2407107") %>% View()
audit_ex <- audit_files %>% filter(`_id` == "2407107")
df_ex <- df %>% filter(`_id` == "2407107")
audit_ex
View(audit_ex)
df_ex
View(df_ex)
View(time_issues)
audit_ex
audit_ex
audit_ex <- audit_files_length%>% filter(`_id` == "2407107")
sum(audit_ex$duration)
sum(audit_ex$duration,na.rm = T)
max(audit_ex$start_int)
(max(audit_ex$start_int) - min(audit_ex$end_int) / 60000)
max(audit_ex$start_int)
min(audit_ex$end_int)
(max(audit_ex$start_int) - min(audit_ex$end_int, na.rm = T) / 60000)
max(audit_ex$start_int) - min(audit_ex$end_int, na.rm = T)
max(audit_ex$start_int) - min(audit_ex$end_int, na.rm = T) / 60000)
max(audit_ex$start_int) - min(audit_ex$end_int, na.rm = T) / 60000
(max(audit_ex$start_int) - min(audit_ex$end_int, na.rm = T)) / 60000
audit_ex
time_delta %>% filter(`_id` == "2407107")
View(audit_ex)
audit_files %>%
filter(event %in% c("group_questions", "question")
)
<<<<<<< Updated upstream
mutate(duration = (end_int - start_int ) / 60000)
audit_files %>%
filter(event %in% c("group_questions", "question") %>%
mutate(duration = (end_int - start_int ) / 60000)
audit_files_length <- audit_files %>%
filter(event %in% c("group_questions", "question") %>%
mutate(duration = (end_int - start_int ) / 60000))
audit_files_length <- audit_files %>%
filter(event %in% c("group_questions", "question")) %>%
mutate(duration = (end_int - start_int ) / 60000)
audit_ex <- audit_files_length %>% filter(`_id` == "2407107")
View(audit_ex)
sum(audit_ex$duration)
df_ex
df_ex$interview_duration
df_ex$end
df_ex$start - df_ex$end
time_delta
time_delta %>%
filter(time_delta > 10)
audit_files_length %>%
group_by(`_id`)
audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = end - start)
audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = end - start)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = max(end, na.rm = T) - min(start, na.rm = T))
View(iv_lengths)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000)
View(iv_lengths)
audit_files_length <- audit_files %>%
#  filter(event %in% c("group_questions", "question")) %>%
mutate(duration = (end_int - start_int ) / 60000)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000)
View(iv_lengths)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000) %>%
mutate(iv_len - iv_min_max)
View(iv_lengths)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000) %>%
mutate(sum_vs_length = iv_len - iv_min_max)
View(iv_lengths)
time_delta <- df %>%
select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
View(time_delta)
View(time_issues)
View(df_ex)
View(audit_ex)
View(audit_files_length)
audit_files_length <- audit_files %>%
#  filter(event %in% c("group_questions", "question")) %>%
mutate(duration = (end_int - start_int ) / 60000)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000) %>%
mutate(sum_vs_length = iv_len - iv_min_max)
View(iv_lengths)
time_delta <- df %>%
select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
View(time_delta)
View(time_issues)
audit_files_length <- audit_files %>%
#  filter(event %in% c("group_questions", "question")) %>%
mutate(metadata_duration = (end_int - start_int ) / 60000)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000) %>%
mutate(sum_vs_length = iv_len - iv_min_max)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(duration, na.rm = T),
iv_min_max = (max(end_int, na.rm = T) - min(end_int, na.rm = T)) / 60000) %>%
mutate(sum_vs_length = iv_len - iv_min_max)
audit_files_length
audit_files_length %>%
group_by(`_id`)
audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(duration, na.rm = T))
audit_files_length %>%
group_by(`_id`) %>%
summarise(iv_len = sum(duration, na.rm = T))
rlang::last_trace()
iv_lengths %>% filter(`_id` == "2403525")
audit_files_length <- audit_files %>%
#  filter(event %in% c("group_questions", "question")) %>%
mutate(metadata_duration = (end_int - start_int ) / 60000)
audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(duration, na.rm = T))
audit_files_length
audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(metadata_duration, na.rm = T))
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(metadata_duration, na.rm = T))
time_delta <- df %>%
select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - iv_len)
time_delta <- df %>%
select(enum_name, `_id`, interview_duration) %>%
left_join(iv_lengths) %>%
mutate(time_delta = interview_duration - metadata_iv_len)
View(time_delta)
time_issues <- time_delta %>%
filter(iv_len < 30,
interview_duration > 30,
time_delta > 10)
time_issues <- time_delta %>%
filter(metadata_iv_len < 30,
interview_duration > 30,
time_delta > 10)
View(time_issues)
audit_ex <- audit_files_length %>% filter(`_id` == "50035")
View(audit_ex)
audit_ex <- audit_files_length %>% filter(`_id` == "69935")
audit_files_length
audit_ex <- audit_files_length %>% filter(`_id` == "2404211")
View(audit_ex)
View(time_delta)
levels(audit_files_length$event)
unqiue(audit_files_length$event)
unique(audit_files_length$event)
audit_files_length %>% filter(event == "form exit")
time_delta %>%
filter(time_delta < 0)
time_delta %>%
filter(time_delta > 10)
time_delta %>%
filter(time_delta > 10 | time_delta < -10)
View(iv_lengths)
iv_lengths %>% filter(metadata_iv_len > 25)
iv_lengths %>% filter(metadata_iv_len < 25)
iv_lengths %>% filter(metadata_iv_len < 20)
iv_lengths %>%
filter(iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 45) +
scale_x_continuous(breaks = seq(0, 120, 10))
iv_lengths %>%
filter(metadata_iv_len < 120) %>%
ggplot(aes(iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 45) +
scale_x_continuous(breaks = seq(0, 120, 10))
iv_lengths %>%
filter(metadata_iv_len < 120) %>%
ggplot(aes(metadata_iv_len)) +
geom_histogram(binwidth = 2) +
geom_vline(xintercept = 45) +
scale_x_continuous(breaks = seq(0, 120, 10))
audit_files_length <- audit_files %>%
mutate(metadata_duration = (end_int - start_int ) / 60000)
iv_lengths <- audit_files_length %>%
group_by(`_id`) %>%
summarise(metadata_iv_len = sum(metadata_duration, na.rm = T))
time_delta <- df %>%
select(enum_name, `_id`) %>%
left_join(iv_lengths)
time_delta
?t
metadata_duration_exclusion <- time_delta %>%
filter(time_delta > 10 | time_delta < -10)
time_delta <- df %>%
select(enum_name, `_id`) %>%
left_join(iv_lengths)
time_delta
View(time_delta)
time_delta %>%
filter(time_delta < 25)
time_delta %>%
filter(metadata_iv_len < 25)
=======
)
############ data cleaning ############
outlier_excluded_questions <- questions %>%
filter(type != 'integer') %>%
pull(name) %>%
unique()
# intersect between the dataset and the kobo tool questions to make sure we get a clean list
excluded_questions_in_data <- intersect(colnames(df), outlier_excluded_questions)
df <- df %>%
left_join(field_officer_location, by = join_by(district_name == district))
df <- df %>%
left_join(field_officer_location, by = join_by(idp_code == `CCCM IDP Site Code`))
rm(list = ls())
today <- Sys.Date()
date_time_now <- format(Sys.time(), "%b_%d_%Y_%H%M%S")
if (!require("pacman")) install.packages("pacman")
if (!require("robotoolbox")) remotes::install_gitlab("dickoa/robotoolbox") ## install if needed robotoolbox
if (!require("ImpactFunctions")) remotes::install_github("alex-stephenson/ImpactFunctions") ## install some key functions made for SOM REACH
p_load(rio,
tidyverse,
koboquest,
hypegrammaR,
sjmisc,
keyring)
# load packages
library(cleaninginspectoR, quietly = T)
library(koboAPI, quietly = T)
library(cleaningtools, quietly = T)
library(robotoolbox, quietly = T)
library(ImpactFunctions)
library(openxlsx)
library(readxl)
library(dplyr)
# library(butteR)
library(data.table)
library(stringr)
library(stringi)
library(lubridate)
library(DT)
library(kableExtra)
library(ggplot2)
library(purrr)
## Hard code values
consent <- "consent"
mindur <- 25
maxdur <- 120
## Set this to TRUE if you want to select the date through the bat file. If FALSE you need to set the date in the script.
dynamic_date <- FALSE ## if false the date must be set in line 184
## set this if you want to access the data from the server. If you are going to choose the file choose TRUE
access_from_server <- TRUE ## if false the file will be manually selected
#to make the scripts reusable relative file paths should be used
user_login <- Sys.info()[["user"]]
wd_path <- sprintf(r"(C:/Users/%s/ACTED/IMPACT SOM - 02_Research/01_REACH/2024_25/03_DDSU/SOM2204 _DSA VIII 2025/03_Data_Analysis/DSA_VIII_Scripts)", user_login)
setwd(wd_path)
rm(list = ls())
today <- Sys.Date()
date_time_now <- format(Sys.time(), "%b_%d_%Y_%H%M%S")
if (!require("pacman")) install.packages("pacman")
if (!require("robotoolbox")) remotes::install_gitlab("dickoa/robotoolbox") ## install if needed robotoolbox
if (!require("ImpactFunctions")) remotes::install_github("alex-stephenson/ImpactFunctions") ## install some key functions made for SOM REACH
p_load(rio,
tidyverse,
koboquest,
hypegrammaR,
sjmisc,
keyring)
# load packages
library(cleaninginspectoR, quietly = T)
library(koboAPI, quietly = T)
library(cleaningtools, quietly = T)
library(robotoolbox, quietly = T)
library(ImpactFunctions)
library(openxlsx)
library(readxl)
library(dplyr)
# library(butteR)
library(data.table)
library(stringr)
library(stringi)
library(lubridate)
library(DT)
library(kableExtra)
library(ggplot2)
library(purrr)
## Hard code values
consent <- "consent"
mindur <- 25
maxdur <- 120
## Set this to TRUE if you want to select the date through the bat file. If FALSE you need to set the date in the script.
dynamic_date <- FALSE ## if false the date must be set in line 184
## set this if you want to access the data from the server. If you are going to choose the file choose TRUE
access_from_server <- TRUE ## if false the file will be manually selected
#to make the scripts reusable relative file paths should be used
user_login <- Sys.info()[["user"]]
>>>>>>> Stashed changes
